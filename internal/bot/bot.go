package bot

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"net/http"
	"os"
	"strconv"
	"strings"
	"sync"
	"time"

	"telegram-reminder/internal/config"
	"telegram-reminder/internal/logger"

	"github.com/go-co-op/gocron"
	openai "github.com/sashabaranov/go-openai"
	tb "gopkg.in/telebot.v3"
)

// EnhancedSystemCompletion combines web search results with OpenAI completions
func EnhancedSystemCompletion(ctx context.Context, client *openai.Client, prompt string, model string) (string, error) {
	// –ü—Ä–æ—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π SystemCompletion –±–µ–∑ –≤–µ–±-–ø–æ–∏—Å–∫–∞
	return SystemCompletion(ctx, client, prompt, model)
}

// Prompt templates
const (
	DailyBriefPrompt = `
–¢—ã ‚Äî Telegram-–±–æ—Ç –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞. –ì–æ–≤–æ—Ä–∏—à—å –∫—Ä–∞—Ç–∫–æ, –¥–µ—Ä–∑–∫–æ, –ø–∞–Ω–∏–±—Ä–∞—Ç—Å–∫–∏.

üìÖ –í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–π –≤–µ–±-–ø–æ–∏—Å–∫ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π.

–ó–∞–ø–æ–ª–Ω–∏ –±–ª–æ–∫–∏:
‚ö° –ú–∏–∫—Ä–æ–¥–µ–π—Å—Ç–≤–∏–µ (–æ–¥–Ω–æ –ø—Ä–æ—Å—Ç–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –Ω–∞ —Å–µ–≥–æ–¥–Ω—è)
üß† –¢–µ–º–∞ –¥–Ω—è (–º–∏–Ω–∏‚Äë–∏–Ω—Å–∞–π—Ç/–º—ã—Å–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏—Ö —Å–æ–±—ã—Ç–∏–π)
üí∞ –ß—Ç–æ –∑–∞–ª—É—Ç–∞—Ç—å (–∞–∫—Ç–∏–≤/–∏–¥–µ—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏—Ö —Ç—Ä–µ–Ω–¥–æ–≤)
üèûÔ∏è –ó–µ–º–ª—è –Ω–∞ –ø—Ä–∏—Å–º–æ—Ç—Ä (–ª–æ—Ç—ã –≤ —é–∂–Ω–æ–º –ü–æ–¥–º–æ—Å–∫–æ–≤—å–µ: –ë—É—Ç–æ–≤–æ, –©–µ—Ä–±–∏–Ω–∫–∞, –ü–æ–¥–æ–ª—å—Å–∫, –í–æ—Å–∫—Ä–µ—Å–µ–Ω—Å–∫)
ü™ô –ê–ª—å—Ç –¥–Ω—è (–∞–∫—Ç—É–∞–ª—å–Ω–∞—è –º–æ–Ω–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏—Ö –¥–≤–∏–∂–µ–Ω–∏–π, –ª–∏–Ω–∫ CoinGecko)
üöÄ –ü—É—à–∫–∞ —Å ProductHunt (—Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–µ —Ç–æ–ø–æ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã)

üîç –í–ï–ë-–ü–û–ò–°–ö: –ù–∞–π–¥–∏ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ —Ç–µ–º–∞–º:
- –ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã –∏ DeFi
- –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏ —Å—Ç–∞—Ä—Ç–∞–ø—ã
- –ù–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å –∏ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏
- –ë–∏–∑–Ω–µ—Å-—Ç—Ä–µ–Ω–¥—ã

–í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–π –≤–µ–±-–ø–æ–∏—Å–∫ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∏ –≤–∫–ª—é—á–∞–π —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏.

–§–æ—Ä–º–∞—Ç–∏—Ä—É–π –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º –¥–ª—è Telegram, –±–µ–∑ –ª–∏—à–Ω–µ–π –≤–æ–¥—ã.
`

	LunchIdeaPrompt = `
üöÄ –ë–ò–ó–ù–ï–°-–ò–î–ï–Ø –ù–ê –°–ï–ì–û–î–ù–Ø

–ü–æ–¥–∞–≤–∞–π –æ–¥–Ω—É –±–∏–∑–Ω–µ—Å‚Äë–∏–¥–µ—é –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏—Ö —Ç—Ä–µ–Ω–¥–æ–≤ –∏ —Å–æ–±—ã—Ç–∏–π.
–ü—Ä–∏–º–µ—Ä–Ω—ã–π –ø–ª–∞–Ω –∏–∑ 4‚Äë5 –ø—É–Ω–∫—Ç–æ–≤ —Å–æ —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã.
–°—Ç–∏–ª—å –ø–∞–Ω–∏–±—Ä–∞—Ç—Å–∫–∏–π, –º–∏–Ω–∏–º—É–º –≤–æ–¥—ã.
–ò—Å–ø–æ–ª—å–∑—É–π –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞.

–§–æ—Ä–º–∞—Ç–∏—Ä—É–π –¥–ª—è Telegram —Å —ç–º–æ–¥–∑–∏ –∏ —á–µ—Ç–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π.
`
)

const OpenAITimeout = 40 * time.Second
const BlockchainTimeout = 10 * time.Second

const Version = "0.1.0"

// formatOpenAIError —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –æ—à–∏–±–∫—É OpenAI –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
func formatOpenAIError(err error, model string) string {
	errStr := err.Error()

	// –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –æ—à–∏–±–∫–∏ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
	switch {
	case strings.Contains(errStr, "insufficient_quota"):
		return "‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫—Ä–µ–¥–∏—Ç–æ–≤ –Ω–∞ –∞–∫–∫–∞—É–Ω—Ç–µ OpenAI\nüí° –ü–æ–ø–æ–ª–Ω–∏—Ç–µ –±–∞–ª–∞–Ω—Å –Ω–∞ platform.openai.com"

	case strings.Contains(errStr, "invalid_api_key"):
		return "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á OpenAI\nüí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ OPENAI_API_KEY –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö"

	case strings.Contains(errStr, "model_not_found"):
		return fmt.Sprintf("‚ùå –ú–æ–¥–µ–ª—å %s –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞\nüí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ /model gpt-4o", model)

	case strings.Contains(errStr, "rate_limit"):
		return "‚è≥ –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤\nüí° –ü–æ–¥–æ–∂–¥–∏—Ç–µ –Ω–µ–º–Ω–æ–≥–æ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞"

	case strings.Contains(errStr, "timeout"):
		return "‚è∞ –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è\nüí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å"

	case strings.Contains(errStr, "context deadline exceeded"):
		return "‚è∞ –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è\nüí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å"

	case strings.Contains(errStr, "network"):
		return "üåê –ü—Ä–æ–±–ª–µ–º—ã —Å —Å–µ—Ç—å—é\nüí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É"

	case strings.Contains(errStr, "unauthorized"):
		return "üîê –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏\nüí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ API –∫–ª—é—á OpenAI"

	default:
		return fmt.Sprintf("‚ùå –û—à–∏–±–∫–∞ OpenAI: %s\nüí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /model gpt-4o", errStr)
	}
}

var baseCommands = []string{
	"/chat <—Å–æ–æ–±—â–µ–Ω–∏–µ> ‚Äì –∑–∞–¥–∞—Ç—å –±–æ—Ç—É –≤–æ–ø—Ä–æ—Å",
	"/ping ‚Äì –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è",
	"/start ‚Äì –¥–æ–±–∞–≤–∏—Ç—å —Ç–µ–∫—É—â–∏–π —á–∞—Ç –≤ —Ä–∞—Å—Å—ã–ª–∫—É",
	"/whitelist ‚Äì –ø–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –ø–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã—Ö —á–∞—Ç–æ–≤",
	"/remove <id> ‚Äì —É–±—Ä–∞—Ç—å —á–∞—Ç –∏–∑ —Å–ø–∏—Å–∫–∞",
	"/model [–∏–º—è] ‚Äì –ø–æ–∫–∞–∑–∞—Ç—å –∏–ª–∏ —Å–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é gpt-4o)",
	"/lunch ‚Äì –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ –∑–∞–ø—Ä–æ—Å–∏—Ç—å –∏–¥–µ–∏ –Ω–∞ –æ–±–µ–¥",
	"/brief ‚Äì –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ –∑–∞–ø—Ä–æ—Å–∏—Ç—å –≤–µ—á–µ—Ä–Ω–∏–π –¥–∞–π–¥–∂–µ—Å—Ç",
	"/crypto ‚Äì –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç",
	"/tech ‚Äì —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –¥–∞–π–¥–∂–µ—Å—Ç",
	"/realestate ‚Äì –¥–∞–π–¥–∂–µ—Å—Ç –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏",
	"/business ‚Äì –±–∏–∑–Ω–µ—Å-–¥–∞–π–¥–∂–µ—Å—Ç",
	"/investment ‚Äì –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç",
	"/startup ‚Äì —Å—Ç–∞—Ä—Ç–∞–ø-–¥–∞–π–¥–∂–µ—Å—Ç",
	"/global ‚Äì –≥–ª–æ–±–∞–ª—å–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç",
	"/tasks ‚Äì –≤—ã–≤–µ—Å—Ç–∏ —Ç–µ–∫—É—â–µ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á",
	"/task [–∏–º—è] ‚Äì —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –∏–ª–∏ –∑–∞–ø—É—Å–∫ –≤—ã–±—Ä–∞–Ω–Ω–æ–π",
	"/blockchain ‚Äì –º–µ—Ç—Ä–∏–∫–∏ —Å–µ—Ç–∏ –±–∏—Ç–∫–æ–∏–Ω–∞",
}

func buildCommandsList(tasks []Task) string {
	var sb strings.Builder
	for _, cmd := range baseCommands {
		sb.WriteString(cmd)
		sb.WriteByte('\n')
	}
	if len(tasks) > 0 {
		sb.WriteString("\n–ö–æ–º–∞–Ω–¥—ã –∑–∞–¥–∞—á (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞—é—Ç—Å—è –∏–∑ tasks.yml):\n")
		names := []string{}
		for _, t := range tasks {
			if t.Name != "" {
				names = append(names, "/"+t.Name)
			}
		}
		sb.WriteString(strings.Join(names, ", "))
	}
	return sb.String()
}

const (
	DefaultLunchTime = "13:00"
	DefaultBriefTime = "20:00"
)

// Task represents a scheduled job definition.
type Task struct {
	Name   string `json:"name" yaml:"name"`
	Prompt string `json:"prompt" yaml:"prompt"`
	Time   string `json:"time,omitempty" yaml:"time,omitempty"`
	Cron   string `json:"cron,omitempty" yaml:"cron,omitempty"`
	Model  string `json:"model,omitempty" yaml:"model,omitempty"`
}

var (
	CurrentModel = "gpt-4o" // –ú–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å –≤–µ–±-–ø–æ–∏—Å–∫–æ–º
	ModelMu      sync.RWMutex
	BasePrompt   string
	// SupportedModels contains all OpenAI model identifiers that support web search and tools
	SupportedModels = []string{
		// Models with web search and tools support
		"gpt-4o",
		"gpt-4o-2024-05-13",
		"gpt-4o-2024-08-06",
		"gpt-4o-2024-11-20",
		"chatgpt-4o-latest",
		"gpt-4o-mini",
		"gpt-4o-mini-2024-07-18",
		"gpt-4-turbo",
		"gpt-4-turbo-2024-04-09",
		"gpt-4-0125-preview",
		"gpt-4-1106-preview",
		"gpt-4-turbo-preview",
		"gpt-4-vision-preview",
		"gpt-4",
		"gpt-4.1",
		"gpt-4.1-2025-04-14",
		"gpt-4.1-mini",
		"gpt-4.1-mini-2025-04-14",
		"gpt-4.1-nano",
		"gpt-4.1-nano-2025-04-14",
		"gpt-4.5-preview",
		"gpt-4.5-preview-2025-02-27",
		"o1-mini",
		"o1-mini-2024-09-12",
		"o1-preview",
		"o1-preview-2024-09-12",
		"o1",
		"o1-2024-12-17",
		"o3",
		"o3-2025-04-16",
		"o3-mini",
		"o3-mini-2025-01-31",
		"o4-mini",
		"o4-mini-2025-04-16",
	}
)

// IsSupportedModel returns true if the given model is in the SupportedModels list.
func IsSupportedModel(m string) bool {
	for _, sm := range SupportedModels {
		if sm == m {
			return true
		}
	}
	return false
}

var (
	LoadedTasks []Task
	TasksMu     sync.RWMutex
)

// applyTemplate replaces placeholders in the prompt with runtime values.
func applyTemplate(prompt, model string) string {
	vars := map[string]string{
		"base_prompt":  BasePrompt,
		"date":         time.Now().Format("2006-01-02"),
		"exchange_api": os.Getenv("EXCHANGE_API"),
		"chart_path":   os.Getenv("CHART_PATH"),
		"model":        model,
	}
	for k, v := range vars {
		prompt = strings.ReplaceAll(prompt, "{"+k+"}", v)
	}
	return prompt
}

// RegisterTaskCommands creates bot handlers for all named tasks.
func RegisterTaskCommands(b *tb.Bot, client *openai.Client) {
	TasksMu.RLock()
	tasks := append([]Task(nil), LoadedTasks...)
	TasksMu.RUnlock()
	for _, t := range tasks {
		if t.Name == "" {
			continue
		}
		tcopy := t
		cmd := "/" + t.Name
		b.Handle(cmd, func(c tb.Context) error {
			ctx, cancel := context.WithTimeout(context.Background(), OpenAITimeout)
			defer cancel()
			model := CurrentModel
			if tcopy.Model != "" {
				model = tcopy.Model
			}
			prompt := applyTemplate(tcopy.Prompt, model)
			resp, err := SystemCompletion(ctx, client, prompt, model)
			if err != nil {
				logger.L.Error("openai error", "task", tcopy.Name, "model", model, "err", err)
				return c.Send(formatOpenAIError(err, model))
			}
			return c.Send(resp)
		})
	}
}

// scheduleDailyMessages sets up the daily lunch idea and brief messages.
func ScheduleDailyMessages(s *gocron.Scheduler, client *openai.Client, b *tb.Bot, chatID int64) {
	tasks, err := LoadTasks()
	if err != nil {
		logger.L.Error("load tasks", "err", err)
		return
	}

	TasksMu.Lock()
	LoadedTasks = tasks
	TasksMu.Unlock()

	for _, t := range tasks {
		tcopy := t
		job := func() {
			ctx, cancel := context.WithTimeout(context.Background(), OpenAITimeout)
			defer cancel()

			model := CurrentModel
			if tcopy.Model != "" {
				model = tcopy.Model
			}

			log.Printf("running task: %s", tcopy.Name)
			prompt := applyTemplate(tcopy.Prompt, model)
			resp, err := SystemCompletion(ctx, client, prompt, model)
			if err != nil {
				logger.L.Error("openai error", "scheduled_task", tcopy.Name, "model", model, "err", err)
				// –î–ª—è –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é, —Ç–æ–ª—å–∫–æ –ª–æ–≥–∏—Ä—É–µ–º
				return
			}
			text := resp
			if chatID != 0 {
				if _, err := b.Send(tb.ChatID(chatID), text); err != nil {
					log.Printf("telegram send error: %v", err)
				} else {
					log.Printf("sent to chat_id: %d", chatID)
				}
				return
			}
			ids, err := LoadWhitelist()
			if err != nil {
				logger.L.Error("load whitelist", "err", err)
				return
			}
			for _, id := range ids {
				if _, err := b.Send(tb.ChatID(id), text); err != nil {
					log.Printf("telegram send error: %v", err)
				} else {
					log.Printf("sent to chat_id: %d", id)
				}
			}
		}

		var jerr error
		switch {
		case t.Cron != "":
			_, jerr = s.Cron(t.Cron).Do(job)
		default:
			timeStr := t.Time
			if timeStr == "" {
				timeStr = "00:00"
			}
			_, jerr = s.Every(1).Day().At(timeStr).Do(job)
		}
		if jerr != nil {
			logger.L.Error("schedule job", "err", jerr)
		}
	}
}

// SendStartupMessage notifies the chat that the bot is running.
func SendStartupMessage(b *tb.Bot, chatID int64, msg string) {
	if chatID != 0 {
		if _, err := b.Send(tb.ChatID(chatID), msg); err != nil {
			logger.L.Error("telegram send", "err", err)
		}
		return
	}
	ids, err := LoadWhitelist()
	if err != nil {
		logger.L.Error("load whitelist", "err", err)
		return
	}
	for _, id := range ids {
		if _, err := b.Send(tb.ChatID(id), msg); err != nil {
			logger.L.Error("telegram send", "err", err)
		}
	}
}

// --- HANDLER FUNCTIONS ---

func handlePing(c tb.Context) error {
	return c.Send("pong")
}

func handleStart(c tb.Context) error {
	if err := AddIDToWhitelist(c.Chat().ID); err != nil {
		log.Printf("whitelist add: %v", err)
	}
	return c.Send("–ë–æ—Ç –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω")
}

func handleWhitelist(c tb.Context) error {
	ids, err := LoadWhitelist()
	if err != nil {
		log.Printf("load whitelist: %v", err)
		return c.Send("whitelist error")
	}
	if len(ids) == 0 {
		return c.Send("Whitelist is empty")
	}
	return c.Send(FormatWhitelist(ids))
}

func handleRemove(c tb.Context) error {
	payload := strings.TrimSpace(c.Message().Payload)
	if payload == "" {
		return c.Send("Usage: /remove <id>")
	}
	id, err := strconv.ParseInt(payload, 10, 64)
	if err != nil {
		return c.Send("Bad ID")
	}
	if err := RemoveIDFromWhitelist(id); err != nil {
		log.Printf("remove id: %v", err)
		return c.Send("remove error")
	}
	return c.Send("Removed")
}

func handleTasks(c tb.Context) error {
	TasksMu.RLock()
	tasks := append([]Task(nil), LoadedTasks...)
	TasksMu.RUnlock()
	return c.Send(FormatTasks(tasks))
}

func handleTask(client *openai.Client) func(tb.Context) error {
	return func(c tb.Context) error {
		name := strings.TrimSpace(c.Message().Payload)
		TasksMu.RLock()
		tasks := append([]Task(nil), LoadedTasks...)
		TasksMu.RUnlock()
		if name == "" {
			return c.Send(FormatTaskNames(tasks))
		}
		t, ok := FindTask(tasks, name)
		if !ok {
			return c.Send("unknown task")
		}
		ctx, cancel := context.WithTimeout(context.Background(), OpenAITimeout)
		defer cancel()
		model := CurrentModel
		if t.Model != "" {
			model = t.Model
		}
		prompt := applyTemplate(t.Prompt, model)
		resp, err := SystemCompletion(ctx, client, prompt, model)
		if err != nil {
			logger.L.Error("openai error", "task", t.Name, "model", model, "err", err)
			return c.Send(formatOpenAIError(err, model))
		}
		return c.Send(resp)
	}
}

func handleModel() func(tb.Context) error {
	return func(c tb.Context) error {
		payload := strings.TrimSpace(c.Message().Payload)
		if payload == "" {
			ModelMu.RLock()
			cur := CurrentModel
			ModelMu.RUnlock()
			return c.Send(fmt.Sprintf(
				"Current model: %s\nSupported: %s",
				cur, strings.Join(SupportedModels, ", "),
			))
		}
		if !IsSupportedModel(payload) {
			return c.Send("unsupported model")
		}
		ModelMu.Lock()
		CurrentModel = payload
		ModelMu.Unlock()
		return c.Send(fmt.Sprintf("Model set to %s", payload))
	}
}

func handleLunch(client *openai.Client) func(tb.Context) error {
	return func(c tb.Context) error {
		ctx, cancel := context.WithTimeout(context.Background(), OpenAITimeout)
		defer cancel()
		model := CurrentModel
		prompt := applyTemplate(LunchIdeaPrompt, model)
		resp, err := SystemCompletion(ctx, client, prompt, model)
		if err != nil {
			logger.L.Error("openai error", "command", "lunch", "model", model, "err", err)
			return c.Send(formatOpenAIError(err, model))
		}
		return c.Send(resp)
	}
}

func handleBrief(client *openai.Client) func(tb.Context) error {
	return func(c tb.Context) error {
		ctx, cancel := context.WithTimeout(context.Background(), OpenAITimeout)
		defer cancel()
		model := CurrentModel
		prompt := applyTemplate(DailyBriefPrompt, model)
		resp, err := SystemCompletion(ctx, client, prompt, model)
		if err != nil {
			logger.L.Error("openai error", "command", "brief", "model", model, "err", err)
			return c.Send(formatOpenAIError(err, model))
		}
		return c.Send(resp)
	}
}

func handleBlockchain(apiURL string) func(tb.Context) error {
	return func(c tb.Context) error {
		ctx, cancel := context.WithTimeout(context.Background(), BlockchainTimeout)
		defer cancel()
		req, err := http.NewRequestWithContext(ctx, http.MethodGet, apiURL, nil)
		if err != nil {
			logger.L.Error("blockchain req", "err", err)
			return c.Send("blockchain error")
		}
		resp, err := http.DefaultClient.Do(req)
		if err != nil {
			logger.L.Error("blockchain call", "err", err)
			return c.Send("blockchain error")
		}
		defer func() {
			if err := resp.Body.Close(); err != nil {
				logger.L.Error("failed to close response body", "err", err)
			}
		}()
		if resp.StatusCode != http.StatusOK {
			logger.L.Error("blockchain status", "status", resp.Status)
			return c.Send("blockchain error")
		}
		var st struct {
			MarketPriceUSD float64 `json:"market_price_usd"`
			NTx            int64   `json:"n_tx"`
			HashRate       float64 `json:"hash_rate"`
		}
		if err := json.NewDecoder(resp.Body).Decode(&st); err != nil {
			logger.L.Error("blockchain decode", "err", err)
			return c.Send("blockchain error")
		}
		msg := fmt.Sprintf("BTC price: $%.2f\nTransactions: %d\nHash rate: %.2f", st.MarketPriceUSD, st.NTx, st.HashRate)
		return c.Send(msg)
	}
}

func handleChat(client *openai.Client) func(tb.Context) error {
	return func(c tb.Context) error {
		q := strings.TrimSpace(c.Message().Payload)
		if q == "" {
			return c.Send("Usage: /chat <message>")
		}
		ctx, cancel := context.WithTimeout(context.Background(), OpenAITimeout)
		defer cancel()
		resp, err := UserCompletion(ctx, client, q, CurrentModel)
		if err != nil {
			logger.L.Error("openai error", "command", "chat", "model", CurrentModel, "err", err)
			return c.Send(formatOpenAIError(err, CurrentModel))
		}
		_, err = c.Bot().Send(c.Sender(), resp)
		return err
	}
}

// –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –¥–ª—è –Ω–æ–≤—ã—Ö –∫–æ–º–∞–Ω–¥ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤
func handleCryptoDigest(client *openai.Client) func(tb.Context) error {
	return func(c tb.Context) error {
		ctx, cancel := context.WithTimeout(context.Background(), OpenAITimeout)
		defer cancel()
		model := CurrentModel
		prompt := applyTemplate(CryptoDigestPrompt, model)
		resp, err := EnhancedSystemCompletion(ctx, client, prompt, model)
		if err != nil {
			logger.L.Error("openai error", "digest", "crypto", "model", model, "err", err)
			return c.Send(formatOpenAIError(err, model))
		}
		return c.Send(resp)
	}
}

func handleTechDigest(client *openai.Client) func(tb.Context) error {
	return func(c tb.Context) error {
		ctx, cancel := context.WithTimeout(context.Background(), OpenAITimeout)
		defer cancel()
		model := CurrentModel
		prompt := applyTemplate(TechDigestPrompt, model)
		resp, err := EnhancedSystemCompletion(ctx, client, prompt, model)
		if err != nil {
			logger.L.Error("openai error", "digest", "tech", "model", model, "err", err)
			return c.Send(formatOpenAIError(err, model))
		}
		return c.Send(resp)
	}
}

func handleRealEstateDigest(client *openai.Client) func(tb.Context) error {
	return func(c tb.Context) error {
		ctx, cancel := context.WithTimeout(context.Background(), OpenAITimeout)
		defer cancel()
		model := CurrentModel
		prompt := applyTemplate(RealEstateDigestPrompt, model)
		resp, err := EnhancedSystemCompletion(ctx, client, prompt, model)
		if err != nil {
			logger.L.Error("openai error", "digest", "realestate", "model", model, "err", err)
			return c.Send(formatOpenAIError(err, model))
		}
		return c.Send(resp)
	}
}

func handleBusinessDigest(client *openai.Client) func(tb.Context) error {
	return func(c tb.Context) error {
		ctx, cancel := context.WithTimeout(context.Background(), OpenAITimeout)
		defer cancel()
		model := CurrentModel
		prompt := applyTemplate(BusinessDigestPrompt, model)
		resp, err := EnhancedSystemCompletion(ctx, client, prompt, model)
		if err != nil {
			logger.L.Error("openai error", "digest", "business", "model", model, "err", err)
			return c.Send(formatOpenAIError(err, model))
		}
		return c.Send(resp)
	}
}

func handleInvestmentDigest(client *openai.Client) func(tb.Context) error {
	return func(c tb.Context) error {
		ctx, cancel := context.WithTimeout(context.Background(), OpenAITimeout)
		defer cancel()
		model := CurrentModel
		prompt := applyTemplate(InvestmentDigestPrompt, model)
		resp, err := EnhancedSystemCompletion(ctx, client, prompt, model)
		if err != nil {
			logger.L.Error("openai error", "digest", "investment", "model", model, "err", err)
			return c.Send(formatOpenAIError(err, model))
		}
		return c.Send(resp)
	}
}

func handleStartupDigest(client *openai.Client) func(tb.Context) error {
	return func(c tb.Context) error {
		ctx, cancel := context.WithTimeout(context.Background(), OpenAITimeout)
		defer cancel()
		model := CurrentModel
		prompt := applyTemplate(StartupDigestPrompt, model)
		resp, err := EnhancedSystemCompletion(ctx, client, prompt, model)
		if err != nil {
			logger.L.Error("openai error", "digest", "startup", "model", model, "err", err)
			return c.Send(formatOpenAIError(err, model))
		}
		return c.Send(resp)
	}
}

func handleGlobalDigest(client *openai.Client) func(tb.Context) error {
	return func(c tb.Context) error {
		ctx, cancel := context.WithTimeout(context.Background(), OpenAITimeout)
		defer cancel()
		model := CurrentModel
		prompt := applyTemplate(GlobalDigestPrompt, model)
		resp, err := EnhancedSystemCompletion(ctx, client, prompt, model)
		if err != nil {
			logger.L.Error("openai error", "digest", "global", "model", model, "err", err)
			return c.Send(formatOpenAIError(err, model))
		}
		return c.Send(resp)
	}
}

// Run initializes and starts the Telegram bot.
func Run(cfg config.Config) error {
	b, err := New(cfg)
	if err != nil {
		return err
	}
	return b.Start()
}
